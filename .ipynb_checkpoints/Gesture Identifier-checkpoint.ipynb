{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello noobs\n",
      "axel was here\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "print(\"hello noobs\")\n",
    "print('axel was here')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = [\"open_palm\",\n",
    "             \"open_dorsal\",\n",
    "             \"fist_palm\",\n",
    "             \"fist_dorsal\",\n",
    "             \"three_fingers_palm\",\n",
    "             \"three_fingers_dorsal\"]\n",
    "\n",
    "img_path = 'img'\n",
    "video_path = 'videos'\n",
    "dataset = pd.read_csv('video_data.csv')\n",
    "ids = ['102', '159', '294', '441', '564', '576', '609', '666', '711', '723']\n",
    "\n",
    "columns=[]\n",
    "#Lägger in alla \"punkter\" (kolumnerna i csv) i en lista, ex. palm_thumb_1_x, \n",
    "for col in dataset.columns[5:]:\n",
    "    columns.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoden videosToFrames behöver köras endast en gång, då loopar den genom alla id's och sparar ner alla videos som frames i följande mappstruktur: \n",
    "\n",
    "/hand-classifier\n",
    "    /img\n",
    "        /open_palm\n",
    "            /102\n",
    "                0.jpg\n",
    "                1.jpg osv...\n",
    "\n",
    "Alla bilder tar mycket plats tillsammans dock, landar någonstans kring 3-4 GB så vet inte riktigt hur vi gör med det."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videosToFrames():\n",
    "    n=0\n",
    "    \n",
    "    for current_id in ids:\n",
    "        the_path = str(video_path + '/' + current_id)\n",
    "        print('Current id: ' + str(current_id))\n",
    "        for video_name in gestures:\n",
    "            complete_video_path = str(the_path + '/' + video_name + '.webm')\n",
    "            cap = cv2.VideoCapture(complete_video_path)\n",
    "            i=0\n",
    "            while(cap.isOpened()):\n",
    "                ret, frame = cap.read()\n",
    "                if ret == False:\n",
    "                    break\n",
    "                cv2.imwrite(img_path + '/' + video_name + '/' + current_id + '/' + str(i)+'.png', frame)\n",
    "                i+=1\n",
    "                \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print('video: ' + video_name + ' is done')\n",
    "            \n",
    "            \n",
    "# Kör metoden\n",
    "#videosToFrames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainingImgs():\n",
    "    limit=2\n",
    "\n",
    "    training_data = []\n",
    "    \n",
    "    \n",
    "    for row in dataset.itertuples(index=True, name='Frame'):\n",
    "        current_id = str(row[1])\n",
    "        gesture = str(row[4] + '_' + row[5])\n",
    "        frame = row[3]\n",
    "        \n",
    "        path = 'img/'+gesture+'/'+current_id+'/{}.png'\n",
    "        \n",
    "        #print('current_id: ' + str(current_id))\n",
    "        #print('current gesture: ' + gesture)\n",
    "        #print('current frame: '+ str(frame))\n",
    "        print('path: '+ path)\n",
    "        \n",
    "        location = path.format(frame)\n",
    "        img = cv2.imread(location)\n",
    "        \n",
    "        #Loop through all points, i.e. the 40 columns\n",
    "        for idx, column in enumerate(columns):\n",
    "            \n",
    "            #Make sure the loop doesnt run out of array\n",
    "            if idx+1 < len(columns):\n",
    "                    \n",
    "                #Gets nextcolumn from next \"string\" in the columns array\n",
    "                nextColumn=columns[idx+1]\n",
    "                \n",
    "            #Makes sure that each coordinate pair (x,y) is taken, basically jumps over each other column    \n",
    "            if idx % limit == 0:\n",
    "                #Gets coordinates pairwise \n",
    "                coords = (int(getattr(row, column)), int(getattr(row, nextColumn)))\n",
    "                    \n",
    "                #checks that first coord in pair is not 0\n",
    "                if(coords[0] > 1):\n",
    "                    x1 = coords[0]-5\n",
    "                    x2 = coords[0]+5\n",
    "                    y1 = coords[1]-5\n",
    "                    y2 = coords[1]+5\n",
    "                                \n",
    "                    training_img = img[y1:y2, x1:x2]\n",
    "                    training_data.append([training_img, column])\n",
    "\n",
    "getTrainingImgs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
