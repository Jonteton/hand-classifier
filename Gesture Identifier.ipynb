{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello noobs\n",
      "axel was here\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "print(\"hello noobs\")\n",
    "print('axel was here')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gestures = [\"open_palm\",\n",
    "             \"open_dorsal\",\n",
    "             \"fist_palm\",\n",
    "             \"fist_dorsal\",\n",
    "             \"three_fingers_palm\",\n",
    "             \"three_fingers_dorsal\"]\n",
    "\n",
    "img_path = 'img'\n",
    "video_path = 'videos'\n",
    "dataset = pd.read_csv('video_data.csv')\n",
    "ids = ['102', '159', '294', '441', '564', '576', '609', '666', '711', '723']\n",
    "\n",
    "columns=[]\n",
    "#Lägger in alla \"punkter\" (kolumnerna i csv) i en lista, ex. palm_thumb_1_x, \n",
    "for col in dataset.columns[5:]:\n",
    "    columns.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoden videosToFrames behöver köras endast en gång, då loopar den genom alla id's och sparar ner alla videos som frames i följande mappstruktur: \n",
    "\n",
    "/hand-classifier\n",
    "    /img\n",
    "        /open_palm\n",
    "            /102\n",
    "                0.jpg\n",
    "                1.jpg osv...\n",
    "\n",
    "Alla bilder tar mycket plats tillsammans dock, landar någonstans kring 3-4 GB så vet inte riktigt hur vi gör med det."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def videosToFrames():\n",
    "    n=0\n",
    "    \n",
    "    for current_id in ids:\n",
    "        the_path = str(video_path + '/' + current_id)\n",
    "        print('Current id: ' + str(current_id))\n",
    "        for video_name in gestures:\n",
    "            complete_video_path = str(the_path + '/' + video_name + '.webm')\n",
    "            cap = cv2.VideoCapture(complete_video_path)\n",
    "            i=0\n",
    "            while(cap.isOpened()):\n",
    "                ret, frame = cap.read()\n",
    "                if ret == False:\n",
    "                    break\n",
    "                cv2.imwrite(img_path + '/' + video_name + '/' + current_id + '/' + str(i)+'.png', frame)\n",
    "                i+=1\n",
    "                \n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print('video: ' + video_name + ' is done')\n",
    "            \n",
    "            \n",
    "# Kör metoden\n",
    "#videosToFrames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b60e198a66f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                     \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mgetTrainingImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-b60e198a66f0>\u001b[0m in \u001b[0;36mgetTrainingImgs\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Frame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mcurrent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mgesture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "def getTrainingImgs():\n",
    "    limit=2\n",
    "\n",
    "    training_data = []\n",
    "    \n",
    "    \n",
    "    for row in dataset.itertuples(index=True, name='Frame'):\n",
    "        current_id = str(row[1])\n",
    "        gesture = str(row[4] + '_' + row[5])\n",
    "        frame = row[3]\n",
    "        \n",
    "        path = 'img/'+gesture+'/'+current_id+'/{}.png'\n",
    "        \n",
    "        #print('current_id: ' + str(current_id))\n",
    "        #print('current gesture: ' + gesture)\n",
    "        #print('current frame: '+ str(frame))\n",
    "        print('path: '+ path)\n",
    "        \n",
    "        location = path.format(frame)\n",
    "        img = cv2.imread(location)\n",
    "        \n",
    "        #Loop through all points, i.e. the 40 columns\n",
    "        for idx, column in enumerate(columns):\n",
    "            \n",
    "            #Make sure the loop doesnt run out of array\n",
    "            if idx+1 < len(columns):\n",
    "                    \n",
    "                #Gets nextcolumn from next \"string\" in the columns array\n",
    "                nextColumn=columns[idx+1]\n",
    "                \n",
    "            #Makes sure that each coordinate pair (x,y) is taken, basically jumps over each other column    \n",
    "            if idx % limit == 0:\n",
    "                label = column.replace('_x','')\n",
    "                #Gets coordinates pairwise \n",
    "                coords = (int(getattr(row, column)), int(getattr(row, nextColumn)))\n",
    "                    \n",
    "                #checks that first coord in pair is not 0\n",
    "                if(coords[0] > 1):\n",
    "                    x1 = coords[0]-5\n",
    "                    x2 = coords[0]+5\n",
    "                    y1 = coords[1]-5\n",
    "                    y2 = coords[1]+5\n",
    "                                \n",
    "                    training_img = img[y1:y2, x1:x2]\n",
    "                    training_data.append([training_img, label])\n",
    "\n",
    "getTrainingImgs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0e7581cd6fd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "random.shuffle(training_data)\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for feature,label in training_data:\n",
    "    X_train.append(feature)\n",
    "    Y_train.append(label)\n",
    "\n",
    "Y_train = np.array(Y)\n",
    "X_train = np.array(X).reshape(-1,10,10,3)\n",
    "\n",
    "encoder = sk.preprocessing.OneHotEncoder(dtype=np.float32)\n",
    "encoder.fit(Y_train.reshape((-1, 1)))\n",
    "\n",
    "Y_train_encoded = encoder.transform(Y_train.reshape((-1, 1))).toarray()\n",
    "#Y_test_encoded = encoder.transform(Y_test.reshape((-1, 1))).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    alpha=1e-4\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(11,11)))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(400, activation='sigmoid'))\n",
    "    model.add(tf.keras.layers.Dense(10))\n",
    "    model.add(tf.keras.layers.Softmax())\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=alpha),\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                  metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
    "                 )\n",
    "  \n",
    "    return model\n",
    "                  \n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
